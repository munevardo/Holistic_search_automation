# üöÄ Advanced SEO Data Processing & Automation Script

## üìÑ Overview

This repository hosts a state-of-the-art Python script designed to streamline and automate complex technical SEO workflows. By leveraging advanced data manipulation libraries, this tool ingests raw crawl data, performs deep cleaning and segmentation, and generates actionable, production-ready reports.

The script eliminates manual data handling, transforming hours of spreadsheet management into a seconds-long automated process, ensuring data integrity and consistency for high-level decision-making.

## ‚ú® Key Features

* **High-Performance Data Processing:** Utilizes **Pandas** for efficient ingestion and manipulation of large datasets, capable of handling thousands of rows without performance bottlenecks.
* **Automated Auditing Logic:** Programmatically identifies critical technical issues such as status code errors (4xx/5xx), missing metadata, heavy assets, and indexing directives.
* **Dynamic Reporting:** Automatically generates comprehensive Excel reports with segmented sheets, categorizing issues by priority and type for immediate team action.
* **Headless Execution:** Designed to run in the background, making it ideal for scheduled jobs (CRON) or integration into larger CI/CD pipelines.
* **Scalable Architecture:** Modular code structure allowing for easy addition of new audit parameters or data sources without refactoring the core logic.

## üõ†Ô∏è Technical Stack

* **Language:** Python 3.x
* **Data Analysis:** Pandas / NumPy
* **File Handling:** OpenPyXL / XlsxWriter
* **Environment:** Cross-platform (Windows/macOS/Linux)

## ‚ö° Usage

1.  **Setup:** Install dependencies via `requirements.txt`.
2.  **Input:** Place your raw crawl data (CSV/Excel) in the designated input directory.
3.  **Run:** Execute the main script via terminal:
    ```bash
    python main.py
    ```
4.  **Output:** Retrieve the processed, multi-tab audit report from the output folder.

## üîß Customization

The script is built with configuration variables at the top level, allowing you to easily adjust thresholds (e.g., max image size, title length limits) and input/output paths to fit your specific project requirements.

## ü§ù Contributing

Contributions to optimize the data processing algorithms or add new audit checks are welcome. Please ensure any pull requests maintain the code's focus on performance and modularity.
